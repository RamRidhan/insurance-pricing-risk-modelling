{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QRtt7lDYiEuz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import psutil\n",
        "import platform\n",
        "\n",
        "# Load data\n",
        "df_train = pd.read_csv('/content/df_train_part2_20250212.csv').drop(columns=['Unnamed: 0'])\n",
        "\n",
        "# Define target variables\n",
        "df_train['PurePremium'] = df_train['ClaimAmount'] / df_train['Exposure']\n",
        "df_train['Frequency'] = df_train['ClaimNb'] / df_train['Exposure']\n",
        "df_severity = df_train[df_train['ClaimAmount'] > 0].copy()\n",
        "df_severity['Severity'] = df_severity['ClaimAmount'] / df_severity['ClaimNb']\n",
        "\n",
        "# Split data into features and targets\n",
        "categorical_features = ['Power', 'Brand', 'Gas', 'Region']\n",
        "numerical_features = ['CarAge', 'DriverAge', 'Density']\n",
        "\n",
        "# Frequency data\n",
        "X = df_train.drop(columns=['ClaimAmount', 'PurePremium', 'Frequency'])\n",
        "y_freq = df_train['Frequency']\n",
        "weights_freq = df_train['Exposure']\n",
        "\n",
        "# Severity data\n",
        "X_sev = df_severity.drop(columns=['ClaimAmount', 'PurePremium', 'Frequency', 'Severity'])\n",
        "y_sev = df_severity['Severity']\n",
        "weights_sev = df_severity['ClaimNb']\n",
        "\n",
        "# Split into train/test sets (frequency)\n",
        "X_train_freq, X_test_freq, y_train_freq, y_test_freq, w_train_freq, w_test_freq = train_test_split(\n",
        "    X, y_freq, weights_freq, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Split into train/test sets (severity)\n",
        "X_train_sev, X_test_sev, y_train_sev, y_test_sev, w_train_sev, w_test_sev = train_test_split(\n",
        "    X_sev, y_sev, weights_sev, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOEC7IykVDs3"
      },
      "source": [
        "**GLM (POISSON+GAMMA)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1utYQOsiWHe",
        "outputId": "b888c1d4-20fb-4fce-f264-a8083f561687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLM (Poisson + Gamma): R²=-0.152, MSE=159769529.0, MAE=4604.2\n",
            "Training Time: 0.3s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import PoissonRegressor, GammaRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import time\n",
        "\n",
        "# Define the preprocessor\n",
        "categorical_features = [\"Power\", \"Brand\", \"Gas\", \"Region\"]\n",
        "numerical_features = [\"CarAge\", \"DriverAge\", \"Density\"]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Frequency: Poisson GLM\n",
        "start = time.time()\n",
        "model_freq = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', PoissonRegressor(max_iter=1000))\n",
        "])\n",
        "model_freq.fit(X_train_freq, y_train_freq, regressor__sample_weight=w_train_freq)\n",
        "train_time_freq = time.time() - start\n",
        "\n",
        "# Severity: Gamma GLM\n",
        "start = time.time()\n",
        "model_sev = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', GammaRegressor(max_iter=1000))\n",
        "])\n",
        "model_sev.fit(X_train_sev, y_train_sev, regressor__sample_weight=w_train_sev)\n",
        "train_time_sev = time.time() - start\n",
        "\n",
        "# Ensure w_test_freq is aligned with the samples used for prediction\n",
        "common_index = X_test_freq.index.intersection(X_test_sev.index)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_freq_common = model_freq.predict(X_test_freq.loc[common_index])\n",
        "y_pred_sev_common = model_sev.predict(X_test_sev.loc[common_index])\n",
        "\n",
        "# Calculate the combined predictions for Pure Premium\n",
        "y_pred_pure_premium = y_pred_freq_common * y_pred_sev_common\n",
        "y_true_pure_premium = y_test_freq.loc[common_index] * y_test_sev.loc[common_index]\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "r2 = r2_score(y_true_pure_premium, y_pred_pure_premium)\n",
        "mse = mean_squared_error(y_true_pure_premium, y_pred_pure_premium)\n",
        "mae = mean_absolute_error(y_true_pure_premium, y_pred_pure_premium)\n",
        "\n",
        "\n",
        "print(f\"GLM (Poisson + Gamma): R²={r2:.3f}, MSE={mse:.1f}, MAE={mae:.1f}\")\n",
        "print(f\"Training Time: {train_time_freq + train_time_sev:.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CddaQXnmVLfm"
      },
      "source": [
        "**RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeBwIGtfibu9",
        "outputId": "cc39e8df-2216-4d03-d3c2-e63d806883b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest: R²=-0.151, MSE=159733754.4, MAE=4633.5\n",
            "Training Time (Random Forest): 613.6s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Frequency: Random Forest\n",
        "start = time.time()\n",
        "model_freq_rf = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "model_freq_rf.fit(X_train_freq, y_train_freq, regressor__sample_weight=w_train_freq)\n",
        "train_time_freq_rf = time.time() - start\n",
        "\n",
        "# Severity: Random Forest\n",
        "start = time.time()\n",
        "model_sev_rf = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "model_sev_rf.fit(X_train_sev, y_train_sev, regressor__sample_weight=w_train_sev)\n",
        "train_time_sev_rf = time.time() - start\n",
        "\n",
        "# Predictions\n",
        "y_pred_freq_rf = model_freq_rf.predict(X_test_freq.loc[common_index])\n",
        "y_pred_sev_rf = model_sev_rf.predict(X_test_sev.loc[common_index])\n",
        "\n",
        "# Compute Pure Premium\n",
        "y_pred_pure_premium_rf = y_pred_freq_rf * y_pred_sev_rf\n",
        "\n",
        "# Evaluate Random Forest Models\n",
        "r2_rf = r2_score(y_true_pure_premium, y_pred_pure_premium_rf)\n",
        "mse_rf = mean_squared_error(y_true_pure_premium, y_pred_pure_premium_rf)\n",
        "mae_rf = mean_absolute_error(y_true_pure_premium, y_pred_pure_premium_rf)\n",
        "\n",
        "print(f\"Random Forest: R²={r2_rf:.3f}, MSE={mse_rf:.1f}, MAE={mae_rf:.1f}\")\n",
        "print(f\"Training Time (Random Forest): {train_time_freq_rf + train_time_sev_rf:.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDopsmmAVPHX"
      },
      "source": [
        "**XGBOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737yJh-nAlrF",
        "outputId": "08434a97-8175-44a5-9938-d835e552d1e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade scikit-learn\n",
        "!pip install --upgrade xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEVvPJeLGblI",
        "outputId": "4cbc570f-778f-4dfe-f2c2-3c1fa77afc8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost: R²=-0.153, MSE=159993081.3, MAE=4632.7\n",
            "Training Time (XGBoost): 6.2s\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# One-Hot Encode categorical features\n",
        "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "X_train_freq_encoded = encoder.fit_transform(X_train_freq[categorical_features])\n",
        "X_test_freq_encoded = encoder.transform(X_test_freq[categorical_features])\n",
        "X_train_sev_encoded = encoder.transform(X_train_sev[categorical_features])  # Match encoding\n",
        "X_test_sev_encoded = encoder.transform(X_test_sev[categorical_features])  # Match encoding\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_freq_scaled = scaler.fit_transform(X_train_freq[numerical_features])\n",
        "X_test_freq_scaled = scaler.transform(X_test_freq[numerical_features])\n",
        "X_train_sev_scaled = scaler.transform(X_train_sev[numerical_features])  # Match scaling\n",
        "X_test_sev_scaled = scaler.transform(X_test_sev[numerical_features])  # Match scaling\n",
        "\n",
        "# Ensure training and test sets have the same number of records\n",
        "X_train_freq_final = np.hstack([X_train_freq_scaled, X_train_freq_encoded])\n",
        "X_test_freq_final = np.hstack([X_test_freq_scaled, X_test_freq_encoded])\n",
        "X_train_sev_final = np.hstack([X_train_sev_scaled, X_train_sev_encoded])\n",
        "X_test_sev_final = np.hstack([X_test_sev_scaled, X_test_sev_encoded])\n",
        "\n",
        "# Convert indices into NumPy boolean masks\n",
        "test_freq_mask = X_test_freq.index.isin(X_test_sev.index)\n",
        "test_sev_mask = X_test_sev.index.isin(X_test_freq.index)\n",
        "\n",
        "# Filter test sets using boolean masks\n",
        "X_test_freq_final = X_test_freq_final[test_freq_mask]\n",
        "X_test_sev_final = X_test_sev_final[test_sev_mask]\n",
        "y_test_freq_aligned = y_test_freq[test_freq_mask]\n",
        "y_test_sev_aligned = y_test_sev[test_sev_mask]\n",
        "\n",
        "# XGBoost Frequency Model\n",
        "start = time.time()\n",
        "model_freq_xgb = XGBRegressor(objective=\"count:poisson\", random_state=42)\n",
        "model_freq_xgb.fit(X_train_freq_final, y_train_freq, sample_weight=w_train_freq)\n",
        "train_time_freq = time.time() - start\n",
        "\n",
        "# XGBoost Severity Model\n",
        "start = time.time()\n",
        "model_sev_xgb = XGBRegressor(objective=\"reg:gamma\", random_state=42)\n",
        "model_sev_xgb.fit(X_train_sev_final, y_train_sev, sample_weight=w_train_sev)\n",
        "train_time_sev = time.time() - start\n",
        "\n",
        "# Predictions (on aligned test set)\n",
        "y_pred_freq_xgb = model_freq_xgb.predict(X_test_freq_final)\n",
        "y_pred_sev_xgb = model_sev_xgb.predict(X_test_sev_final)\n",
        "\n",
        "# Compute Pure Premium\n",
        "y_pred_pure_premium_xgb = y_pred_freq_xgb * y_pred_sev_xgb\n",
        "y_true_pure_premium = y_test_freq_aligned * y_test_sev_aligned\n",
        "\n",
        "# Evaluate XGBoost Model\n",
        "results = {\n",
        "    \"Model\": \"XGBoost\",\n",
        "    \"R2\": r2_score(y_true_pure_premium, y_pred_pure_premium_xgb),\n",
        "    \"MSE\": mean_squared_error(y_true_pure_premium, y_pred_pure_premium_xgb),\n",
        "    \"MAE\": mean_absolute_error(y_true_pure_premium, y_pred_pure_premium_xgb)\n",
        "}\n",
        "\n",
        "# Print results\n",
        "print(f\"XGBoost: R²={results['R2']:.3f}, MSE={results['MSE']:.1f}, MAE={results['MAE']:.1f}\")\n",
        "print(f\"Training Time (XGBoost): {train_time_freq + train_time_sev:.1f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JC4C0pkVSAJ"
      },
      "source": [
        "**LIGHT GBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzA1ovEjib1F",
        "outputId": "e33e6891-5889-424f-b53a-17dc147937c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM: R²=-198643848652276992.000, MSE=27560791199832655557296128.0, MAE=330054576665.8\n",
            "Training Time (LightGBM): 2.4s\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "import time\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Frequency Model: LightGBM\n",
        "start = time.time()\n",
        "model_freq_lgb = LGBMRegressor(\n",
        "    objective='poisson',\n",
        "    verbose=-1  )\n",
        "model_freq_lgb.fit(X_train_freq, y_train_freq, sample_weight=w_train_freq)\n",
        "train_time_freq_lgb = time.time() - start\n",
        "\n",
        "# Severity Model: LightGBM\n",
        "start = time.time()\n",
        "model_sev_lgb = LGBMRegressor(\n",
        "    objective='gamma',\n",
        "    verbose=-1\n",
        ")\n",
        "model_sev_lgb.fit(X_train_sev, y_train_sev, sample_weight=w_train_sev)\n",
        "train_time_sev_lgb = time.time() - start\n",
        "\n",
        "# Predictions\n",
        "y_pred_freq_lgb = model_freq_lgb.predict(X_test_freq.loc[common_index])\n",
        "y_pred_sev_lgb = model_sev_lgb.predict(X_test_sev.loc[common_index])\n",
        "\n",
        "# Compute Pure Premium\n",
        "y_pred_pure_premium_lgb = y_pred_freq_lgb * y_pred_sev_lgb\n",
        "\n",
        "# Evaluate LightGBM Models\n",
        "r2_lgb = r2_score(y_true_pure_premium, y_pred_pure_premium_lgb)\n",
        "mse_lgb = mean_squared_error(y_true_pure_premium, y_pred_pure_premium_lgb)\n",
        "mae_lgb = mean_absolute_error(y_true_pure_premium, y_pred_pure_premium_lgb)\n",
        "\n",
        "print(f\"LightGBM: R²={r2_lgb:.3f}, MSE={mse_lgb:.1f}, MAE={mae_lgb:.1f}\")\n",
        "print(f\"Training Time (LightGBM): {train_time_freq_lgb + train_time_sev_lgb:.1f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eNG1I4SVo14"
      },
      "source": [
        "**GRADIENT BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIsX_4ppHi8O",
        "outputId": "57c091d1-e733-4dc4-9e2e-5dea5137a764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting: R²=-0.152, MSE=159865994.0, MAE=4607.5\n",
            "Training Time (Gradient Boosting): 52.8s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import time\n",
        "### ----> Gradient Boosting Model: Claim Frequency & Severity <---- ###\n",
        "\n",
        "# Frequency: Gradient Boosting\n",
        "start = time.time()\n",
        "model_freq_gbm = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42))\n",
        "])\n",
        "model_freq_gbm.fit(X_train_freq, y_train_freq, regressor__sample_weight=w_train_freq)\n",
        "train_time_freq_gbm = time.time() - start\n",
        "\n",
        "# Severity: Gradient Boosting\n",
        "start = time.time()\n",
        "model_sev_gbm = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42))\n",
        "])\n",
        "model_sev_gbm.fit(X_train_sev, y_train_sev, regressor__sample_weight=w_train_sev)\n",
        "train_time_sev_gbm = time.time() - start\n",
        "\n",
        "# Predictions\n",
        "y_pred_freq_gbm = model_freq_gbm.predict(X_test_freq.loc[common_index])\n",
        "y_pred_sev_gbm = model_sev_gbm.predict(X_test_sev.loc[common_index])\n",
        "\n",
        "# Compute Pure Premium\n",
        "y_pred_pure_premium_gbm = y_pred_freq_gbm * y_pred_sev_gbm\n",
        "\n",
        "# Evaluate Gradient Boosting Models\n",
        "r2_gbm = r2_score(y_true_pure_premium, y_pred_pure_premium_gbm)\n",
        "mse_gbm = mean_squared_error(y_true_pure_premium, y_pred_pure_premium_gbm)\n",
        "mae_gbm = mean_absolute_error(y_true_pure_premium, y_pred_pure_premium_gbm)\n",
        "\n",
        "print(f\"Gradient Boosting: R²={r2_gbm:.3f}, MSE={mse_gbm:.1f}, MAE={mae_gbm:.1f}\")\n",
        "print(f\"Training Time (Gradient Boosting): {train_time_freq_gbm + train_time_sev_gbm:.1f}s\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WTXc31RVZVt"
      },
      "source": [
        "**CATBOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npNCh11iHz0H",
        "outputId": "302c21e7-de19-45ff-f2b9-14717c1f81f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI_-j1btHi--",
        "outputId": "899ddbe6-44e5-4134-cd1c-b6b32fbc3b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoost: R²=-12.255, MSE=1839019749.4, MAE=9589.2\n",
            "Training Time (CatBoost): 193.7s\n"
          ]
        }
      ],
      "source": [
        "### ----> CatBoost Models: Claim Frequency & Severity <---- ###\n",
        "\n",
        "# Frequency: CatBoost\n",
        "start = time.time()\n",
        "model_freq_cat = CatBoostRegressor(loss_function='Poisson', cat_features=categorical_features, verbose=0)\n",
        "model_freq_cat.fit(X_train_freq, y_train_freq, sample_weight=w_train_freq)\n",
        "train_time_freq_cat = time.time() - start\n",
        "\n",
        "# Severity: CatBoost\n",
        "start = time.time()\n",
        "model_sev_cat = CatBoostRegressor(loss_function='RMSE', cat_features=categorical_features, verbose=0)\n",
        "model_sev_cat.fit(X_train_sev, y_train_sev, sample_weight=w_train_sev)\n",
        "train_time_sev_cat = time.time() - start\n",
        "\n",
        "# Predictions\n",
        "y_pred_freq_cat = model_freq_cat.predict(X_test_freq.loc[common_index])\n",
        "y_pred_sev_cat = model_sev_cat.predict(X_test_sev.loc[common_index])\n",
        "\n",
        "# Compute Pure Premium\n",
        "y_pred_pure_premium_cat = y_pred_freq_cat * y_pred_sev_cat\n",
        "\n",
        "# Evaluate CatBoost Models\n",
        "r2_cat = r2_score(y_true_pure_premium, y_pred_pure_premium_cat)\n",
        "mse_cat = mean_squared_error(y_true_pure_premium, y_pred_pure_premium_cat)\n",
        "mae_cat = mean_absolute_error(y_true_pure_premium, y_pred_pure_premium_cat)\n",
        "\n",
        "print(f\"CatBoost: R²={r2_cat:.3f}, MSE={mse_cat:.1f}, MAE={mae_cat:.1f}\")\n",
        "print(f\"Training Time (CatBoost): {train_time_freq_cat + train_time_sev_cat:.1f}s\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExuIQiaJVuiN"
      },
      "source": [
        "**BAYSEIAN RIDGE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv4hfUxdHjBe",
        "outputId": "01e4be52-13a2-4353-88b7-40db0a661d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bayesian Ridge: R²=-0.151, MSE=159664878.8, MAE=4589.5\n",
            "Training Time (Bayesian Ridge): 2.2s\n"
          ]
        }
      ],
      "source": [
        "### ----> Bayesian Ridge Model: Claim Frequency & Severity <---- ###\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features) # Updated here\n",
        "    ])\n",
        "# Frequency: Bayesian Ridge Regression\n",
        "start = time.time()\n",
        "model_freq_bayes = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', BayesianRidge())\n",
        "])\n",
        "model_freq_bayes.fit(X_train_freq, y_train_freq, regressor__sample_weight=w_train_freq)\n",
        "train_time_freq_bayes = time.time() - start\n",
        "\n",
        "# Severity: Bayesian Ridge Regression\n",
        "start = time.time()\n",
        "model_sev_bayes = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', BayesianRidge())\n",
        "])\n",
        "model_sev_bayes.fit(X_train_sev, y_train_sev, regressor__sample_weight=w_train_sev)\n",
        "train_time_sev_bayes = time.time() - start\n",
        "\n",
        "# Predictions\n",
        "y_pred_freq_bayes = model_freq_bayes.predict(X_test_freq.loc[common_index])\n",
        "y_pred_sev_bayes = model_sev_bayes.predict(X_test_sev.loc[common_index])\n",
        "\n",
        "# Compute Pure Premium\n",
        "y_pred_pure_premium_bayes = y_pred_freq_bayes * y_pred_sev_bayes\n",
        "\n",
        "# Evaluate Bayesian Ridge Models\n",
        "r2_bayes = r2_score(y_true_pure_premium, y_pred_pure_premium_bayes)\n",
        "mse_bayes = mean_squared_error(y_true_pure_premium, y_pred_pure_premium_bayes)\n",
        "mae_bayes = mean_absolute_error(y_true_pure_premium, y_pred_pure_premium_bayes)\n",
        "\n",
        "print(f\"Bayesian Ridge: R²={r2_bayes:.3f}, MSE={mse_bayes:.1f}, MAE={mae_bayes:.1f}\")\n",
        "print(f\"Training Time (Bayesian Ridge): {train_time_freq_bayes + train_time_sev_bayes:.1f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYp6FDfLVywo"
      },
      "source": [
        "**RESULTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY4brKnwJR7g",
        "outputId": "179e8987-5e08-4207-a7ce-be6dc48079c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----------------------+-------------------------+--------------------------------+------------------+---------------------+\n",
            "|    | Model                 |                      R² |                            MSE |              MAE |   Training Time (s) |\n",
            "+====+=======================+=========================+================================+==================+=====================+\n",
            "|  0 | GLM (Poisson + Gamma) |                  -0.152 |                  159769528.995 |         4604.159 |               6.184 |\n",
            "+----+-----------------------+-------------------------+--------------------------------+------------------+---------------------+\n",
            "|  1 | XGBoost               |                  -0.153 |                  159993081.298 |         4632.716 |               7.246 |\n",
            "+----+-----------------------+-------------------------+--------------------------------+------------------+---------------------+\n",
            "|  2 | LightGBM              | -198643848652276992.000 | 27560791199832655557296128.000 | 330054576665.769 |               2.123 |\n",
            "+----+-----------------------+-------------------------+--------------------------------+------------------+---------------------+\n",
            "|  3 | Gradient Boosting     |                  -0.152 |                  159865993.980 |         4607.467 |              42.905 |\n",
            "+----+-----------------------+-------------------------+--------------------------------+------------------+---------------------+\n",
            "|  4 | CatBoost              |                 -12.255 |                 1839019749.350 |         9589.178 |             193.668 |\n",
            "+----+-----------------------+-------------------------+--------------------------------+------------------+---------------------+\n",
            "|  5 | Bayesian Ridge        |                  -0.151 |                  159664878.842 |         4589.493 |               2.235 |\n",
            "+----+-----------------------+-------------------------+--------------------------------+------------------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Create a DataFrame with all model results\n",
        "results_df = pd.DataFrame({\n",
        "    \"Model\": [\"GLM (Poisson + Gamma)\", \"XGBoost\", \"LightGBM\", \"Gradient Boosting\", \"CatBoost\", \"Bayesian Ridge\"],\n",
        "    \"R²\": [r2, results['R2'], r2_lgb, r2_gbm, r2_cat, r2_bayes],\n",
        "    \"MSE\": [mse, results['MSE'], mse_lgb, mse_gbm, mse_cat, mse_bayes],\n",
        "    \"MAE\": [mae, results['MAE'], mae_lgb, mae_gbm, mae_cat, mae_bayes],\n",
        "    \"Training Time (s)\": [\n",
        "        train_time_freq + train_time_sev,\n",
        "        train_time_freq_xgb + train_time_sev_xgb,\n",
        "        train_time_freq_lgb + train_time_sev_lgb,\n",
        "        train_time_freq_gbm + train_time_sev_gbm,\n",
        "        train_time_freq_cat + train_time_sev_cat,\n",
        "        train_time_freq_bayes + train_time_sev_bayes\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Print the results in a well-formatted table\n",
        "print(tabulate(results_df, headers=\"keys\", tablefmt=\"grid\", floatfmt=\".3f\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F73ttK9FPuwD"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
